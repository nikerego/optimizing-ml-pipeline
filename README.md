# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
The dataset contains applications of candidates for a bank service. We are looking to predict a candidate's 
application result based on features included in the dataset such as their job, marital status,...etc. 

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The first part of the process involves setting up the pipeline for cleaning and preprocessing the data for use in our ML pipelines.
This is accomplished with the help of `train.py`. There are then three broad categories which cover the ML pipeline:

**1. Sampling Methods:**

This helps us choose suitable parameters for our model. We have several choices such as random sampling, grid search, 
Bayesian sampling to name a few. These will vary based on the model of interest and can be continuous or discrete values.

**2. Early Stopping Policy:**


**3. Performance Metrics:**

**What are the benefits of the parameter sampler you chose?**

The parameter C is used to prevent over fitting while the max_iter helps reduce the overall compute time. Choice of these
two parameters helps the algorithm search over the appropriate space without and prevents the process from running too long.

**What are the benefits of the early stopping policy you chose?**

I have set the evaluation_interval to 2 and the slack_factor to 0.1. This evaluates the primary metric every 2 iteration 
and if the value falls outside top 10% of the primary metric then the training process will stop. This can prevent over 
fitting to the training data.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
We could do some preliminary EDA on the data prior to fitting the model to get a better understanding of the data.
This would help better understand which features to choose as well as interpret results.

We can look to include additional features as well as derived features. We can also think about collecting
more records as well as updated records to train our model on as time passes. These steps will help us improve overall 
accuracy and prevent data drift.

## Proof of cluster clean up
![cluster_cleanup](proof-of-cluster-cleanup.jpeg)